{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b99576a5",
   "metadata": {},
   "source": [
    "# Notebook for exploring different models and prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc1c89",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c015b412",
   "metadata": {},
   "source": [
    "### Do Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c98356f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite compatibility fix for Streamlit Cloud\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "\n",
    "try:\n",
    "    __import__('pysqlite3')\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from src.rag_system import RAGSystem\n",
    "from src.document_processor import DocumentProcessor\n",
    "from src.vector_store import VectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbd35571",
   "metadata": {},
   "source": [
    "### Go here to figure out which models to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c43956",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "# HuggingFace API configuration\n",
    "api_token = os.getenv(\"HUGGINGFACE_API_TOKEN\")\n",
    "\n",
    "# Initialize OpenAI client with HuggingFace router\n",
    "client = OpenAI(\n",
    "    base_url=\"https://router.huggingface.co/v1\",\n",
    "    api_key=api_token\n",
    ")\n",
    "\n",
    "models = client.models.list()\n",
    "for model in models:\n",
    "    #if 'gpt' in model.id.lower():\n",
    "    print(model.id)\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c554e0c1",
   "metadata": {},
   "source": [
    "### Selected Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c20b70",
   "metadata": {},
   "source": [
    "I hand selected a few models, and then below ran a cost analysis to make sure I wasn't getting into anything too expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86981bad",
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_models = [\n",
    "    'openai/gpt-oss-20b',\n",
    "    'deepseek-ai/DeepSeek-V3-0324',\n",
    "    'google/gemma-3-27b-it',\n",
    "    'meta-llama/Llama-Guard-4-12B'\n",
    "]\n",
    "\n",
    "models_json = [model.model_dump() for model in client.models.list()]\n",
    "\n",
    "for model in models_json:\n",
    "    if model['id'] in selected_models:\n",
    "        lowest_price = None\n",
    "        lowest_provider = None\n",
    "        for provider in model.get('providers', []):\n",
    "            pricing = provider.get('pricing', {})\n",
    "            # Check both input and output prices if available\n",
    "            input_price = pricing.get('input')\n",
    "            output_price = pricing.get('output')\n",
    "            for price in [input_price, output_price]:\n",
    "                if price is not None:\n",
    "                    if lowest_price is None or price < lowest_price:\n",
    "                        lowest_price = price\n",
    "                        lowest_provider = provider.get('provider')\n",
    "        if lowest_price is not None:\n",
    "            print(f\"{model['id']}: {lowest_provider} - {lowest_price}\")\n",
    "        else:\n",
    "            print(f\"{model['id']}: No pricing information available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33eb202",
   "metadata": {},
   "source": [
    "## Data for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687bd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a series of test prompts\n",
    "prompt_list = \\\n",
    "    [\"Tell me about yourself?\", \n",
    "     \"Tell me about your C++ skills?\", \n",
    "     \"Have you worked in Machine Learning?\",\n",
    "     \"Do you have Python Skills?\",\n",
    "     \"Tell me about your python skills?\",\n",
    "     \"What is your favorite color?\",\n",
    "     \"What is the velocity of an unladen swallow?\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca181aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Test Prompts\n",
    "\n",
    "import pandas as pd\n",
    "# prompt_test will be filled with the responses\n",
    "prompt_test = pd.DataFrame(data=prompt_list,columns=[\"prompt\"])\n",
    "\n",
    "\n",
    "for model in selected_models:\n",
    "    print(f\"Testing model: {model}\")\n",
    "    rag_system = RAGSystem(model_name=model)\n",
    "    response = rag_system.query(\"testing to make sure the prompt engine is working\")\n",
    "    if \"difficulties\" in response.lower():\n",
    "        print(f\"Model {model} is broken.\")\n",
    "        continue\n",
    "    prompt_test[model] = [rag_system.query(p) for p in  prompt_test[\"prompt\"]]\n",
    "    \n",
    "    \n",
    "import datetime\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%Y%m%d_%H%M%S\")\n",
    "\n",
    "prompt_test.to_html(f'prompt_test_{timestamp}.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
