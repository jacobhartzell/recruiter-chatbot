{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea161369-b11f-41aa-9499-422b80cc12a6",
   "metadata": {},
   "source": [
    "# Making sure the API works"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a4653e0-7c43-43be-b706-d17bbfd3f44e",
   "metadata": {},
   "source": [
    "## First install all package dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91745625-8b36-42f7-aa9f-38c3b3205ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install uv && uv pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c2746b-052e-4c50-a313-b1262c4d9420",
   "metadata": {},
   "source": [
    "## Then make sure Vertex AI stuff works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f87b63-a285-4630-a33c-a4f3cb43d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.genai.types import Content, CreateCachedContentConfig, HttpOptions, Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdb127f-ed3d-4d1f-ac8b-93b67369fe63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Use the variables\n",
    "PROJECT_ID = os.getenv('GCP_PROJECT_ID')\n",
    "LOCATION = os.getenv('GCP_LOCATION')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63de7f0-d676-40d0-9aae-95779582b45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only run this block for Vertex AI API\n",
    "client = genai.Client(\n",
    "    vertexai=True, project=PROJECT_ID, location=LOCATION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb93fbb2-d6f6-4639-9666-5bfdf616fe33",
   "metadata": {},
   "outputs": [],
   "source": [
    "content_cache_list = client.caches.list()\n",
    "\n",
    "# Access individual properties of a ContentCache object(s)\n",
    "for content_cache in content_cache_list:\n",
    "    print(f\"Cache `{content_cache.name}` for model `{content_cache.model}`\")\n",
    "    print(f\"Last updated at: {content_cache.update_time}\")\n",
    "    print(f\"Expires at: {content_cache.expire_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6eeb4d9-ab26-4c03-9750-f96104b3e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.models.generate_content(\n",
    "    model='gemini-2.0-flash-001', contents='Why is the sky blue?'\n",
    ")\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b87a8e-46c3-43be-b321-bcfa1c8cc4a4",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8814224-8cf8-4d35-8fcc-418cec504749",
   "metadata": {},
   "outputs": [],
   "source": [
    "import vertexai\n",
    "from vertexai import model_garden\n",
    "\n",
    "# TODO(developer): Update and un-comment below lines\n",
    "# PROJECT_ID = \"your-project-id\"\n",
    "vertexai.init(project=PROJECT_ID, location=\"us-central1\")\n",
    "\n",
    "# List deployable models, optionally list Hugging Face models only or filter by model name.\n",
    "deployable_models = model_garden.list_deployable_models(list_hf_models=False, model_filter=\"gemma\")\n",
    "[print(m) for m in deployable_models]\n",
    "\n",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a8c2f8-1445-4877-8bfc-c0a14e9a7de0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7662c07-7fdb-43ef-b375-5677dff5cc1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c460797-0834-4cfb-9fa7-a309cbd4f2f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db5c646-1713-4c84-bc64-9bf31c4016c7",
   "metadata": {},
   "source": [
    "# For refactory llm_interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087b0d22-a7db-48f6-89b9-0c69b9a45636",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQLite compatibility fix for Streamlit Cloud\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "\n",
    "try:\n",
    "    __import__('pysqlite3')\n",
    "    sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "except ImportError:\n",
    "    pass\n",
    "\n",
    "from src.rag_system import RAGSystem\n",
    "from src.document_processor import DocumentProcessor\n",
    "from src.vector_store import VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1888dae-e2f3-42b0-8275-52437cced8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# SQLite compatibility fix for Streamlit Cloud\n",
    "import sys\n",
    "sys.path.append('..') \n",
    "from src.llm_interface import LLMInterface\n",
    "\n",
    "llm = LLMInterface(model_name='gemini-2.0-flash-001')\n",
    "\n",
    "response = llm.generate_response(prompt=\"does this work?\", context=\"Tell me about yourself\")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5059de2-0e45-46dc-a6ce-73fa3a658c90",
   "metadata": {},
   "source": [
    "# Now testing RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3269424-eb2f-4420-adaf-1fbcc51f5a82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2e8e3f-d713-4fc7-b75c-6e29ce46b037",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e5d38-bce3-4539-bcd9-379352941af2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9892ca-8ff5-483e-9cb6-71702a8e1619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m131",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m131"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
